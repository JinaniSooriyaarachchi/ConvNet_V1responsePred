{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvNet_V1responsePred.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinaniSooriyaarachchi/ConvNet_V1responsePred/blob/main/ConvNet_V1responsePred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "E5DZKYQvTiAG"
      },
      "outputs": [],
      "source": [
        "# @title Use Kay Dataset (from V1) with a simple ConvNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install dependencies\n",
        "!pip install Pillow --quiet #Python Imaging Library\n",
        "!pip install torch_intermediate_layer_getter --quiet #to get the intermediate results from chosen submodules\n",
        "\n",
        "#  Imports\n",
        "import copy\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch_intermediate_layer_getter import IntermediateLayerGetter as MidGetter\n",
        "\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.spatial.distance import pdist\n",
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "Dcf_AxUxTqAK",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faafd83a-4230-48c1-a627-40275a9ff0f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for torch-intermediate-layer-getter (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set seed\n",
        "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness. NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "# In case that `DataLoader` is used\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"WARNING: For this notebook to perform best, \"\n",
        "        \"if possible, in the menu under `Runtime` -> \"\n",
        "        \"`Change runtime type.`  select `GPU` \")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook.\")\n",
        "\n",
        "  return device\n",
        "\n",
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()"
      ],
      "metadata": {
        "id": "ZB31pvqduXyv",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c98b6c-3ecb-4423-9409-ec2680fc5d19"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n",
            "GPU is enabled in this notebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Downloading Kay dataset\n",
        "import requests\n",
        "\n",
        "fnames = [\"kay_labels.npy\", \"kay_labels_val.npy\", \"kay_images.npz\"]\n",
        "\n",
        "urls =['https://osf.io/r638s/download',\n",
        "       'https://osf.io/yqb3e/download',\n",
        "       'https://osf.io/ymnjv/download']\n",
        "\n",
        "for i, url in enumerate(urls):\n",
        "  r = requests.get(url, allow_redirects=True)\n",
        "  with open(fnames[i], 'wb') as fh:\n",
        "    fh.write(r.content)\n",
        "\n",
        "\n",
        "with np.load(fnames[2]) as dobj:\n",
        "  dat = dict(**dobj)\n",
        "labels = np.load('kay_labels.npy')\n",
        "val_labels = np.load('kay_labels_val.npy')"
      ],
      "metadata": {
        "id": "Hi6fUyvVTzEP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Stimuli to RGB\n",
        "\n",
        "# Converting stimulus to RGB and changing the scale to 0-255 (Specific to Kay dataset images)\n",
        "\n",
        "stimuli_tr = dat[\"stimuli\"]\n",
        "stimuli_ts = dat[\"stimuli_test\"]\n",
        "stimuli_tr_xformed = np.zeros((1750, 3, 128, 128)) # 1750 x 3 x 128 x 128\n",
        "stimuli_ts_xformed = np.zeros((120, 3, 128, 128)) # 120 x 3 x 128 x 128\n",
        "for i in range(1750):\n",
        "  img = stimuli_tr[i, :, :]\n",
        "  img = ((img - np.min(img))*255/(np.max(img) - np.min(img))).astype(int)\n",
        "  stimuli_tr_xformed[i, :, :, :] = [img,img,img]\n",
        "\n",
        "for i in range(120):\n",
        "  img = stimuli_ts[i, :, :]\n",
        "  img = ((img - np.min(img))*255/(np.max(img) - np.min(img))).astype(int)\n",
        "  stimuli_ts_xformed[i, :, :, :] = [img, img, img]"
      ],
      "metadata": {
        "id": "qdDLY6WHT7jA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up training and test data for V4 region\n",
        "loc_id = np.where(dat['roi'] == 1)\n",
        "response_tr = np.squeeze(dat[\"responses\"][:, loc_id]) # (1750, 928)\n",
        "response_ts = np.squeeze(dat[\"responses_test\"][:, loc_id]) # (120, 928)\n",
        "\n",
        "# normalize response datsets to the range -1,1\n",
        "response_tr=response_tr/np.max(np.abs(response_tr))\n",
        "response_ts=response_ts/np.max(np.abs(response_ts))\n"
      ],
      "metadata": {
        "id": "Qu3_M2yrUDzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "# Custom dataloader for loading images in numpy array\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, data, targets, transform=None):\n",
        "    self.data = data\n",
        "    self.targets = torch.Tensor(targets) #changed here \n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = self.data[index]\n",
        "    y = self.targets[index]\n",
        "\n",
        "    if self.transform:\n",
        "        x = Image.fromarray(self.data[index].astype(np.uint8).transpose(1, 2, 0))\n",
        "        x = self.transform(x)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "                                 transforms.RandomResizedCrop(128), #224\n",
        "                                 transforms.RandomHorizontalFlip(),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                      [0.229, 0.224, 0.225])\n",
        "                                 ]),\n",
        "    'test': transforms.Compose([\n",
        "                               #transforms.Resize(256),\n",
        "                               transforms.CenterCrop(128),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                    [0.229, 0.224, 0.225])\n",
        "                               ]),\n",
        "             }\n",
        "\n",
        "dataset = {}\n",
        "dataset['train'] = MyDataset(list(stimuli_tr_xformed),\n",
        "                             list(response_tr), transform=transform['train'])\n",
        "dataset['test'] = MyDataset(list(stimuli_ts_xformed),\n",
        "                           list(response_ts), transform=transform['test'])\n",
        "\n",
        "dataset_sizes_main = {x: len(dataset[x]) for x in ['train','test']}\n",
        "\n",
        "dataloaders_main = {x: torch.utils.data.DataLoader(dataset[x], batch_size=1750) for x in ['train','test']}"
      ],
      "metadata": {
        "id": "TSmyRxYNURQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            # Defining a 2D convolution layer\n",
        "            nn.Conv2d(3, 8, kernel_size=13, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            #nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            #nn.Linear(222784, 10000),\n",
        "            #nn.Dropout(p=0.5),\n",
        "            #nn.ReLU(inplace=True),\n",
        "            nn.Linear(26912, 1294)           \n",
        "        )\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "bDEZ7lktIEzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net"
      ],
      "metadata": {
        "id": "64cq9qFeIc6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "mean2d\n",
        "\"\"\"\n",
        "def mean2(x):\n",
        "    y = np.sum(x) / np.size(x);\n",
        "    return y\n",
        "\n",
        "\"\"\"\n",
        "matlab 2d correlation\n",
        "\"\"\"\n",
        "def corr2(a,b):\n",
        "  \n",
        "    a = a - mean2(a)\n",
        "    b = b - mean2(b)\n",
        "    r = (a*b).sum() / np.sqrt((a*a).sum() * (b*b).sum());\n",
        "    return r"
      ],
      "metadata": {
        "id": "-1EoQ9vGnSjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define final train and test model function\n",
        "def test_model(model, criterion, optimizer, dataloaders_main, dataset_sizes,num_epochs):\n",
        "\n",
        "  since = time.time()\n",
        "\n",
        "  loss_vec_train = []\n",
        "  loss_vec_test = []\n",
        "  accuracy_test=[]\n",
        "  accuracy_train = []\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
        "    print('-' * 20)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'test']:\n",
        "      if phase == 'train':\n",
        "        model.train()  # Set model to training mode\n",
        "      else:\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "      running_loss = 0.0\n",
        "\n",
        "      # Iterate over data.\n",
        "      for inputs, labels in dataloaders_main[phase]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs.float(), labels.float())\n",
        "\n",
        "\n",
        "        # create correlaitions\n",
        "          outputs_ = outputs.cpu().detach().numpy() #batch_size x n_voxels\n",
        "          labels_ =  labels.cpu().detach().numpy() \n",
        "\n",
        "          correlation=corr2(np.corrcoef(labels_.T),np.corrcoef(outputs_.T))\n",
        "\n",
        "          # backward + optimize only if in training phase\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      epoch_loss = running_loss / dataset_sizes[phase]\n",
        "      print(f\"{phase} Loss: {epoch_loss:.4f}\")\n",
        "      if phase == 'train':\n",
        "        loss_vec_train.append(epoch_loss)\n",
        "        accuracy_train.append(correlation)\n",
        "      if phase == 'test':\n",
        "        loss_vec_test.append(epoch_loss)\n",
        "        accuracy_test.append(correlation)\n",
        "\n",
        "      \n",
        "      # deep copy the model\n",
        "      if phase == 'test':\n",
        "        best_loss = epoch_loss\n",
        "        \n",
        "\n",
        "    print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "  loss_vec = [loss_vec_train, loss_vec_test]\n",
        "\n",
        "  return model, loss_vec, accuracy_test, accuracy_train"
      ],
      "metadata": {
        "id": "hEaV1_TwAeWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up device if it's available \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "criterion = nn.MSELoss() # Keep it at the final epoch\n",
        "n_epochs =  25  # Change this \n",
        "batch_size = 1750\n",
        "\n",
        "net.to(device)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, \n",
        "                      momentum=0.8, weight_decay = 0.1)\n",
        "torch.cuda.empty_cache()\n",
        "net, loss_vec, accuracy_test, accuracy_train = test_model(net, criterion, optimizer, dataloaders_main, dataset_sizes_main, n_epochs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KkZnTTxq_7oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss curves\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.plot(loss_vec[0], linewidth=2)\n",
        "plt.plot(loss_vec[1], linewidth=2)\n",
        "plt.legend([\"Training\" , \"Testing\"])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n"
      ],
      "metadata": {
        "id": "vZ-IpTuPDYkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy curve\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.plot(np.array(accuracy_train))\n",
        "plt.plot(np.array(accuracy_test))\n",
        "plt.legend([\"Training\" , \"Testing\"])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Correlation')"
      ],
      "metadata": {
        "id": "M697bL8R-VF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot conv1 layer weights\n",
        "conv1_weights=net.state_dict()['cnn_layers.0.weight'].cpu().detach().numpy()\n",
        "\n",
        "plt.figure(figsize=(10,35))\n",
        "for filters in range(conv1_weights.shape[0]):\n",
        "  for filters2 in range(conv1_weights.shape[1]):\n",
        "    plt.subplot(8,3,filters*3+filters2+1)\n",
        "    plt.imshow(conv1_weights[filters,filters2,:,:]) #check channel 1 out of 3 channels in conv1 layer\n",
        "plt.tight_layout()   \n",
        " "
      ],
      "metadata": {
        "id": "RVtbaLQuA-r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title define convolution\n",
        "def convolve2D(image, kernel, padding=0, strides=1):\n",
        "    # Cross Correlation\n",
        "    kernel = np.flipud(np.fliplr(kernel))\n",
        "\n",
        "    # Gather Shapes of Kernel + Image + Padding\n",
        "    xKernShape = kernel.shape[0]\n",
        "    yKernShape = kernel.shape[1]\n",
        "    xImgShape = image.shape[0]\n",
        "    yImgShape = image.shape[1]\n",
        "\n",
        "    # Shape of Output Convolution\n",
        "    xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\n",
        "    yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\n",
        "    output = np.zeros((xOutput, yOutput))\n",
        "\n",
        "    # Apply Equal Padding to All Sides\n",
        "    if padding != 0:\n",
        "        imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\n",
        "        imagePadded[int(padding):int(-1 * padding), int(padding):int(-1 * padding)] = image\n",
        "        print(imagePadded)\n",
        "    else:\n",
        "        imagePadded = image\n",
        "\n",
        "    # Iterate through image\n",
        "    for y in range(image.shape[1]):\n",
        "        # Exit Convolution\n",
        "        if y > image.shape[1] - yKernShape:\n",
        "            break\n",
        "        # Only Convolve if y has gone down by the specified Strides\n",
        "        if y % strides == 0:\n",
        "            for x in range(image.shape[0]):\n",
        "                # Go to next row once kernel is out of bounds\n",
        "                if x > image.shape[0] - xKernShape:\n",
        "                    break\n",
        "                try:\n",
        "                    # Only Convolve if x has moved by the specified Strides\n",
        "                    if x % strides == 0:\n",
        "                        output[x, y] = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]).sum()\n",
        "                except:\n",
        "                    break\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xqO96fAGB_qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take image 1 and convolve with 2 filters to see the output\n",
        "plt.figure(figsize=(15, 5))\n",
        "img1=stimuli_tr[2]\n",
        "plt.imshow(img1)\n",
        "plt.title('Original Image')\n",
        "\n",
        "plt.figure(figsize=(10,35))\n",
        "for filters in range(conv1_weights.shape[0]):\n",
        "  for filters2 in range(conv1_weights.shape[1]):\n",
        "    plt.subplot(8,3,filters*3+filters2+1)\n",
        "    plt.imshow(convolve2D(img1,conv1_weights[filters,filters2,:,:],padding=0)) #check channel 1 out of 3 channels in conv1 layer\n",
        "plt.suptitle('V1 representations of the original image')\n",
        "plt.tight_layout()  "
      ],
      "metadata": {
        "id": "5MNsQnw8BEw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overall VAF\n",
        "\n",
        "# Loading validation data and forward pass through the network\n",
        "dataloaders = {x: torch.utils.data.DataLoader(dataset[x], batch_size=120) for x in ['test']}\n",
        "for inputs, labels in dataloaders['test']:\n",
        "  inputs = inputs.to(device)\n",
        "  labels = labels.cpu().detach().numpy()\n",
        "  outputs=net(inputs)\n",
        "  outputs = outputs.cpu().detach().numpy()\n",
        "\n",
        "vaf=np.zeros((1,labels.shape[1]))\n",
        "for vox in range(labels.shape[1]):\n",
        "  pred=outputs[:,vox]\n",
        "  act=labels[:,vox]\n",
        "  vaf[:,vox]=np.corrcoef(pred,act)[0,1]**2\n",
        "\n",
        "# final vaf\n",
        "Final_VAF=np.mean(vaf[0,:])*100\n",
        "print('Final_VAF =',Final_VAF)"
      ],
      "metadata": {
        "id": "JmlpTNPsEb7i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}